<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>big data on Evgenii Karimov</title><link>https://www.karimov.berlin/tags/big-data/</link><description>Recent content in big data on Evgenii Karimov</description><generator>Hugo -- gohugo.io</generator><language>EN</language><lastBuildDate>Tue, 05 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://www.karimov.berlin/tags/big-data/index.xml" rel="self" type="application/rss+xml"/><item><title>Thoughts about the modern data engineering stack</title><link>https://www.karimov.berlin/writing/2022-04-05-thoughts-about-data-stack/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.karimov.berlin/writing/2022-04-05-thoughts-about-data-stack/</guid><description>Random thoughts about the modern data engineering stack - the modern stack should be the best from the beginning, or at least aiming to be so.
It means any required vendor solutions should be onboarded as early as possible, obviously given the platform vision and financial situation at hand.
There&amp;rsquo;s no point re-inventing the wheel unless you&amp;rsquo;re trying to solve a unique use-case, which might be the truth for huge data systems like Netflix or Google has.</description></item><item><title>Reverse ETL - definition and use-cases</title><link>https://www.karimov.berlin/writing/2021-11-18-reverse-etl/</link><pubDate>Sat, 23 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.karimov.berlin/writing/2021-11-18-reverse-etl/</guid><description>In this article I&amp;rsquo;d like to summarise my knowledges and understanding of the new buzzword Reverse ETL.
No long introductions, let&amp;rsquo;s jump into the topic.
Let&amp;rsquo;s start with definitions, what is ETL and Reverse ETL?
ETL (Extract-Transform-Load) - a common term for data integration, a process of bringing data from sources to your datawarehouse, or data lake.
Modern data storage and analytics vendors also recommend utilising ELT approach, when transformations and aggregations happen after the load into the datastore.</description></item><item><title>DWH approaches</title><link>https://www.karimov.berlin/writing/2021-04-30-dwh-structure-approaches/</link><pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate><guid>https://www.karimov.berlin/writing/2021-04-30-dwh-structure-approaches/</guid><description>With this post I&amp;rsquo;d like to cover some well-know approaches to data-warehousing in order to have a brief overview of them:
Inmon Kimball Data Vault Data Lake Lakehouse I&amp;rsquo;m not aiming to cover all the details of each approach in this article, as each of them deserves its own separate article.
Inmon Let&amp;rsquo;s start first with the methodology created by Bill Inmon, which is considered to be a top-down approach. This methodology assumes that the structure of the data is known from top to down, there&amp;rsquo;s a whole picture of it availble and data is modelled accordingly to the 3NF (Normal form).</description></item><item><title>About the modern data engineering stack</title><link>https://www.karimov.berlin/writing/2021-02-22-modern-data-eng-stack/</link><pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate><guid>https://www.karimov.berlin/writing/2021-02-22-modern-data-eng-stack/</guid><description>Not a secret we&amp;rsquo;re living in the rapidly changing world, generating more and more machine data. A new era of big data and so on, words you&amp;rsquo;ve probably heard hundreds of times already. A lot of new and old companies want to get insights out of their data. Become data-driven is a new trend and motto. Naturally many new, open-source tools and projects appeared against this background.
How can they help in democratising data landscape and how does the choice between commercial products/services and open-source/in-house solutions look like in these circumstances?</description></item><item><title>Notes about data catalog solutions</title><link>https://www.karimov.berlin/writing/2021-01-25-data-catalog/</link><pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate><guid>https://www.karimov.berlin/writing/2021-01-25-data-catalog/</guid><description>Data catalogs have become an essential part of the modern data infrastructure and management. It allows to have an overview of data, presented in the organisation, by storing metadata about it - such as location, format, columns/attributes, etc. This is especially important combined with the modern data teams architectures, such as Data Mesh, when every team can contribute to data catalog.
There&amp;rsquo;s a growing interest in the industry to improve productivity of data engineers and scientists with metadata.</description></item></channel></rss>